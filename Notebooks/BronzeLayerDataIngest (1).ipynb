{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2232bc93-2c2e-46ac-aa6b-86d4ca1644f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fce19039-535b-40e0-aa16-9dfa3693067e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimPhysician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcbfbad4-c641-4b03-873a-788a8332a267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    "\n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    "\n",
    "# BRIONZE TABLE DimPhysician\n",
    "@dlt.table(\n",
    "    name=\"DimPhysician\",\n",
    "    comment=\"Raw DimPhysician data for US Healthcare Dynamics\",\n",
    "    table_properties={\"quality\": \"DimPhysician bronze\"}\n",
    ")\n",
    "def drivers_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimPhysician.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9bdcb73-3dc5-46ac-9d9f-3eabf631890f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimTransaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "817a5dd2-a0aa-4d9a-8df4-31c39251482d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    "\n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    "\n",
    "# BRIONZE TABLE DimTransaction\n",
    "@dlt.table(\n",
    "    name=\"DimTransaction\",\n",
    "    comment=\"Raw DimTransaction data for US Healthcare Dynamics\",\n",
    "    table_properties={\"quality\": \"DimTransaction bronze\"}\n",
    ")\n",
    "def drivers_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimTransaction.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "535d307b-98e3-4707-9913-37030968785e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimPayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63b40afb-683e-4727-a6b3-50f1aaeffc51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    "\n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    "\n",
    "# BRIONZE TABLE DimPayor\n",
    "@dlt.table(\n",
    "    name=\"DimPayor\",\n",
    "    comment=\"Raw DimPayor data for US Healthcare Dynamics\",\n",
    "    table_properties={\"quality\": \"DimPayor bronze\"}\n",
    ")\n",
    "def drivers_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimPayer.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "716d55ab-df69-4a47-8a00-7d59c13224d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "FactTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99e12567-6c20-4d5b-8f86-76f321cdb9db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    "\n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    "\n",
    "# BRIONZE TABLE FactTable\n",
    "@dlt.table(\n",
    "    name=\"FactTable\",\n",
    "    comment=\"Raw FactTable data for US Healthcare Dynamics\",\n",
    "    table_properties={\"quality\": \"FactTable bronze\"}\n",
    ")\n",
    "def drivers_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/FactTable.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e78fae7-44b1-4a2b-bfbe-452797ec6899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "CPTCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b89744b-9cd8-4e25-8ab1-d7ca03452edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    " \n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    " \n",
    "# BRONZE TABLE DimCptCode\n",
    "@dlt.table(\n",
    "    name=\"DimCptCode\",\n",
    "    comment=\"Raw CPT Codes data\",\n",
    "    table_properties={\"quality\": \"DimCptCode bronze\"}\n",
    ")\n",
    "def DimCptCode_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimCptCode.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0c73724-4bde-4e46-b648-d0132fed802b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimHospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c952afd0-3baf-4cdd-89b5-8a4562b806b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    " \n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    " \n",
    "# BRIONZE TABLE DimHospital\n",
    "@dlt.table(\n",
    "    name=\"DimHospital\",\n",
    "    comment=\"Raw Hospital data\",\n",
    "    table_properties={\"quality\": \"DimHospital bronze\"}\n",
    ")\n",
    "def DimHospital_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimHospital.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45fa6ed4-99d0-4988-a891-dbde1e230edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimPatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb2e0fc-555f-471f-9400-d36c9f61c941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    " \n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    " \n",
    "@dlt.table(\n",
    "    name=\"DimPatient\",\n",
    "    comment=\"Raw Patient data\",\n",
    "    table_properties={\"quality\": \"DimPatient bronze\"}\n",
    ")\n",
    "def DimPatient_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimPatient.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "107edf34-4584-47ad-9034-92af82eedc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "269c7294-eb3c-4666-bd89-a35d476eafac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    " \n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    " \n",
    "@dlt.table(\n",
    "    name=\"DimDate\",\n",
    "    comment=\"Raw date data for Capstone\",\n",
    "    table_properties={\"quality\": \"DimDate bronze\"}\n",
    ")\n",
    "def DimDate_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimDate.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caf2ad03-2837-4c3a-9245-d31979a7e043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DimDiagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ab20d85-e535-43f3-8a6b-bcff663903a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, lit, col\n",
    " \n",
    "spark.sql(\"USE catalog ushealthcaredynamics\")\n",
    "spark.sql(\"USE SCHEMA  bronze\")\n",
    " \n",
    "@dlt.table(\n",
    "    name=\"DimDiagnosis\",\n",
    "    comment=\"Raw date data for Capstone\",\n",
    "    table_properties={\"quality\": \"DimDiagnosis bronze\"}\n",
    ")\n",
    "def DimDiagnosis_bronze():\n",
    "    return (\n",
    "        spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/ushealthcaredynamics/bronze/ushealthcaredynamics/Datasets/DimDiagnosisCode.csv\")\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        .withColumn(\"source_file\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"audit_source\", lit(\"batch_load\"))\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4583998807513107,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "BronzeLayerDataIngest (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
